# scrapy_paper
软件目的:爬取相关论文网站的信息




软件使用说明:



	管理界面

		设置:
			关于作者
			刷新界面
			关键词修复
			退出

		爬虫:
			选择爬虫
			三大顶会
			爬取结果展示

		搜索:
			搜索

		帮助:
			特别注意
			帮助

		下载地址:
			下载地址


	关键词修复界面



	运行爬虫界面

使用说明:



	在管理界面的爬虫选项选择相对应的爬虫,双击进入后到达运行爬虫界面,输入相关的关键词后选择运行爬虫,下载的文件路径在运行爬虫界面的存放路径里显示.




实现步骤:




	1.编写My_tk.py文件创建主窗口

	2.编写frozen_dir.py确定文件的绝对路径

	3.编写PATHS.py文件,确定配置文件CONFIG_ALL的路径

	4.编写Management.py,用于向文件写入数据

	5.编写RunSpider.py,用于运行爬虫

	6.编写tk_run.py,用于运行爬虫

	7.编写Error_Recovery.py文件对爬虫关键词修复

	8.编写Start_App.py文件,导入运行爬虫所必须的包,打包该文件

	9.使用pyinstaller对Start_App.py打包生成exe文件

	10.使用Inno Setup编译器对生成的exe文件实现可安装